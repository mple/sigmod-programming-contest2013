{"name":"Sigmod-programming-contest2013","tagline":"","body":"SIGMOD Programming Contest 2013\r\n\r\n(a)TeamName: Mple\r\n\r\n(b)Members:\r\n\r\nAlexander Sibetheros, sdi0900261@di.uoa.gr, University of Athens, Department of Informatics and Telecommunications, Undergraduate Student  \r\nJohn Chronis, sdi0900125@di.uoa.gr, University of Athens, Department of Informatics and Telecommunications, Undergraduate Student  \r\nEvangelos Nikolopoulos, sdi0900089@di.uoa.gr, University of Athens, Department of Informatics and Telecommunications, Undergraduate Student  \r\nStavros Petsalakis, sdi0900236@di.uoa.gr, University of Athens, Department of Informatics and Telecommunications, Undergraduate Student\r\nDimitrianos Savva sdi0900018@di.uoa.gr, University of Athens, Department of Informatics and Telecommunications, Undergraduate Student  \r\n\r\n(c)Supervisor:\r\n\r\nHerald Kllapi, herald@di.uoa.gr, Department of Informatics and Telecommunications,Phd Student \r\n\r\n(d)Brief Description\r\n\r\nWe observed a big overlap in queries, tokens and documents. The unique document words are arriving in a linear fashion. This is also true for the unique query words(tokens). So we instrumented our code to de-duplicate queries as whole. Tokens and document words are saved uniquely. So by having two different managers ( one for tokens and one for tokens) we compress the data,\r\nWe use a job scheduling approach to organize the threads.\r\nWe store relations between document words and query tokens based on the type of matching (edit, hamming,exact and 1,2,3). \r\nWhen a document token or query token arrives we search for it in our managers, if it has not already arrived  we insert into our hashmaps  deletion neighborhoods of that token. \r\nWhen we proccess new token word and query token we create new relations between tokens and words.\r\nThe final step is to access our relation and extract which tokens match the document words that are active in a particular batch, after that we create the result that we return.\r\nOur implementation is based on words and token worlds that evolve through time. In every batch we need  to compute relations of new words and tokens which are the Delta of our world and the tokens and words of the current batch. \r\n\r\n\r\n\r\n(e)Third Party Code\r\n-Google Sparse Hash  http://code.google.com/p/sparsehash/ New BSD License\r\n-Google MurMurh Hashing Algorithm http://code.google.com/p/smhasher/ MIT License\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}